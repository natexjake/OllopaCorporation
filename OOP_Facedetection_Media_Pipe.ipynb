{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FuQ5FxGiQJko01e6ZXp6p83xRi3504yT",
      "authorship_tag": "ABX9TyM35GDqM4eUaj4LRt6GDvjp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natexjake/OllopaCorporation/blob/main/OOP_Facedetection_Media_Pipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "Ai_YEydzhBb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retina-face"
      ],
      "metadata": {
        "id": "AED9ay0y3z-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp7vPG8s31Hl",
        "outputId": "14fb15bc-318e-4724-ed25-dfdf745c94b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n"
      ],
      "metadata": {
        "id": "gfQUyeBzhxOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from PIL.Image import fromarray\n",
        "from retinaface import RetinaFace\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import math\n",
        "import PIL\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "8rd2p6fz0Ve2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you install the libraries permanently you can remove the comment"
      ],
      "metadata": {
        "id": "oLNvRRb757g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eQK3D6RFN0xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# package_path = '/content/packages'\n",
        "# sys.path.insert(0,package_path)"
      ],
      "metadata": {
        "id": "JNv71u0VO_ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import mediapipe as mp"
      ],
      "metadata": {
        "id": "zb4AhC-oQflN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def browse_photos():\n",
        "    print('\\n')\n",
        "    print(\"Browsing photos...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename, file_content in uploaded.items():\n",
        "      # Decode the file content as an image\n",
        "      nparr = np.frombuffer(file_content, np.uint8)\n",
        "      img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "      img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      resp = RetinaFace.detect_faces(img_path=filename)  # Use the filename as the path\n",
        "      x1, y1 = resp[\"face_1\"][\"landmarks\"][\"right_eye\"]\n",
        "      x2, y2 = resp[\"face_1\"][\"landmarks\"][\"left_eye\"]\n",
        "      a = abs(y1 - y2)\n",
        "      b = abs(x2 - x1)\n",
        "      c = math.sqrt(a * a + b * b)\n",
        "      cos_alpha = (b * b + c * c - a * a) / (2 * b * c)\n",
        "      alpha = np.arccos(cos_alpha)\n",
        "      alpha = (alpha * 180) / math.pi\n",
        "      aligned_img = fromarray(img_rgb)\n",
        "      aligned_img = np.array(aligned_img.rotate(alpha))\n",
        "      aligned_img_rgb = cv2.cvtColor(aligned_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Face extraction\n",
        "      mp_face_mesh = mp.solutions.face_mesh\n",
        "      face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "      results = face_mesh.process(aligned_img_rgb[:, :, ::-1])\n",
        "      landmarks = results.multi_face_landmarks[0]\n",
        "      face_oval = mp_face_mesh.FACEMESH_FACE_OVAL\n",
        "      df = pd.DataFrame(list(face_oval), columns=[\"p1\", \"p2\"])\n",
        "      routes_idx = []\n",
        "      p1 = df.iloc[0][\"p1\"]\n",
        "      p2 = df.iloc[0][\"p2\"]\n",
        "\n",
        "      for i in range(0, df.shape[0]):\n",
        "          obj = df[df[\"p1\"] == p2]\n",
        "          p1 = obj[\"p1\"].values[0]\n",
        "          p2 = obj[\"p2\"].values[0]\n",
        "          current_route = []\n",
        "          current_route.append(p1)\n",
        "          current_route.append(p2)\n",
        "          routes_idx.append(current_route)\n",
        "\n",
        "      routes = []\n",
        "      for source_idx, target_idx in routes_idx:\n",
        "          source = landmarks.landmark[source_idx]\n",
        "          target = landmarks.landmark[target_idx]\n",
        "          relative_source = (int(source.x * aligned_img_rgb.shape[1]), int(source.y * aligned_img_rgb.shape[0]))\n",
        "          relative_target = (int(target.x * aligned_img_rgb.shape[1]), int(target.y * aligned_img_rgb.shape[0]))\n",
        "          routes.append(relative_source)\n",
        "          routes.append(relative_target)\n",
        "\n",
        "      mask = np.zeros((aligned_img_rgb.shape[0], aligned_img_rgb.shape[1]))\n",
        "      mask = cv2.fillConvexPoly(mask, np.array(routes), 1)\n",
        "      mask = mask.astype(bool)\n",
        "\n",
        "      out = np.zeros_like(aligned_img_rgb)\n",
        "      out[mask] = aligned_img_rgb[mask]\n",
        "\n",
        "      # Display the manipulated image\n",
        "      cv2_imshow(out)"
      ],
      "metadata": {
        "id": "s1XZRDxa4iWI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def use_webcam():\n",
        "    print('\\n')\n",
        "    print(\"Using webcam...\")\n",
        "\n",
        "    # JavaScript code to capture image from webcam\n",
        "    js_code = \"\"\"\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Wait for Capture to be clicked.\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "\n",
        "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "\n",
        "        // Return the captured image data URL\n",
        "        return dataUrl;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the JavaScript code\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "    # Call the JavaScript function to capture the image\n",
        "    data = eval_js('takePhoto(0.8)')\n",
        "\n",
        "    # Convert the captured image data URL to an OpenCV image\n",
        "    img = js_to_image(data)\n",
        "\n",
        "    # Save the captured image\n",
        "    filename = 'captured_image.jpg'\n",
        "    cv2.imwrite(filename, img)\n",
        "    print('Saved to {}'.format(filename))\n",
        "\n",
        "    # Display the captured image\n",
        "    #cv2_imshow(img)\n",
        "\n",
        "    # You can continue processing the captured image as needed\n",
        "    img_base = cv2.imread(\"captured_image.jpg\")\n",
        "\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "    results = face_mesh.process(img)\n",
        "    if results.multi_face_landmarks:\n",
        "        landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "        img = img_base.copy()\n",
        "        # mp_face_mesh.FACEMESH_LEFT_EYE\n",
        "        lip_landmarks = []\n",
        "        for source_idx, target_idx in mp_face_mesh.FACEMESH_LIPS:\n",
        "          source = landmarks.landmark[source_idx]\n",
        "          target = landmarks.landmark[target_idx]\n",
        "\n",
        "          relative_source = (int(source.x * img.shape[1]), int(source.y * img.shape[0]))\n",
        "          relative_target = (int(source.x * img.shape[1]), int(source.y * img.shape[0]))\n",
        "          lip_landmarks.append((source, target))\n",
        "\n",
        "          cv2.line(img, relative_source, relative_target, color = (255, 255, 255), thickness =2)\n",
        "\n",
        "        # Convert the image from BGR to RGB format\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Convert the image back to BGR for display using cv2_imshow\n",
        "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Display the image using OpenCV in Colab\n",
        "        cv2_imshow(img_bgr)\n",
        "\n",
        "        # Assign the converted image to a variable\n",
        "        converted_image = img_bgr\n",
        "    else:\n",
        "        print(\"No face landmarks detected in the image.\")\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename\n",
        "\n",
        "  #Check if the choice is \"2\" (capture image from the camera)\n",
        "  if choice == \"2\":\n",
        "    try:\n",
        "      filename = take_photo('photo.jpg')\n",
        "      print('Saved to {}'.format(filename))\n",
        "\n",
        "      # Show the image which was just taken.\n",
        "      display(Image(filename))\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))\n",
        "\n"
      ],
      "metadata": {
        "id": "0G70QPb4jzkp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    while True:\n",
        "        print(\"Face Detection Program\")\n",
        "        print(\"----------------------\")\n",
        "        print(\"1. Upload an image\")\n",
        "        print(\"2. Capture an image from the camera\")\n",
        "        choice = input(\"Enter your choice (1 or 2): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            browse_photos()\n",
        "        elif choice == \"2\":\n",
        "            use_webcam()\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "        try_again = input(\"Do you want to try again? (yes/no): \")\n",
        "        if try_again.lower() != \"yes\":\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "matqy7ySY8iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EE3L2uWrxu_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}