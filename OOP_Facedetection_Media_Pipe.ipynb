{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FuQ5FxGiQJko01e6ZXp6p83xRi3504yT",
      "authorship_tag": "ABX9TyNjVMMPRYxJywvbOJpw6BZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natexjake/OllopaCorporation/blob/main/OOP_Facedetection_Media_Pipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import PIL\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8rd2p6fz0Ve2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQK3D6RFN0xB",
        "outputId": "c9d9e37b-b714-42b4-e92b-ab826d28db62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "package_path = '/content/packages'\n",
        "sys.path.insert(0,package_path)"
      ],
      "metadata": {
        "id": "JNv71u0VO_ix"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp"
      ],
      "metadata": {
        "id": "zb4AhC-oQflN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def browse_photos():\n",
        "    print('\\n')\n",
        "    print(\"Browsing photos...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Iterate over the uploaded files\n",
        "    for filename, file_content in uploaded.items():\n",
        "        # Decode the file content as an image\n",
        "        nparr = np.frombuffer(file_content, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # Display the uploaded image\n",
        "        # cv2_imshow(img)\n",
        "\n",
        "        mp_face_mesh = mp.solutions.face_mesh\n",
        "        face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
        "        results = face_mesh.process(img[:,:,::-1])\n",
        "        landmarks = results.multi_face_landmarks[0]\n",
        "\n",
        "        face_oval = mp_face_mesh.FACEMESH_FACE_OVAL\n",
        "\n",
        "        df = pd.DataFrame(list(face_oval), columns=[\"p1\", \"p2\"])\n",
        "\n",
        "        routes_idx = []\n",
        "\n",
        "        p1 = df.iloc[0][\"p1\"]\n",
        "        p2 = df.iloc[0][\"p2\"]\n",
        "\n",
        "        for i in range(0, df.shape[0]):\n",
        "            obj = df[df[\"p1\"] == p2]\n",
        "            p1 = obj[\"p1\"].values[0]\n",
        "            p2 = obj[\"p2\"].values[0]\n",
        "\n",
        "            current_route = []\n",
        "            current_route.append(p1)\n",
        "            current_route.append(p2)\n",
        "            routes_idx.append(current_route)\n",
        "\n",
        "        routes = []\n",
        "\n",
        "        for source_idx, target_idx in routes_idx:\n",
        "            source = landmarks.landmark[source_idx]\n",
        "            target = landmarks.landmark[target_idx]\n",
        "\n",
        "            relative_source = (int(source.x * img.shape[1]), int(source.y * img.shape[0]))\n",
        "            relative_target = (int(target.x * img.shape[1]), int(target.y * img.shape[0]))\n",
        "\n",
        "            routes.append(relative_source)\n",
        "            routes.append(relative_target)\n",
        "\n",
        "        mask = np.zeros((img.shape[0], img.shape[1]))\n",
        "        mask = cv2.fillConvexPoly(mask, np.array(routes), 1)\n",
        "        mask = mask.astype(bool)\n",
        "\n",
        "        out = np.zeros_like(img)\n",
        "        out[mask] = img[mask]\n",
        "\n",
        "        # Display the manipulated image\n",
        "        cv2_imshow(out)"
      ],
      "metadata": {
        "id": "s1XZRDxa4iWI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def use_webcam():\n",
        "    print('\\n')\n",
        "    print(\"Using webcam...\")\n",
        "\n",
        "    # JavaScript code to capture image from webcam\n",
        "    js_code = \"\"\"\n",
        "    async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        capture.textContent = 'Capture';\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Wait for Capture to be clicked.\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "\n",
        "        const dataUrl = canvas.toDataURL('image/jpeg', quality);\n",
        "\n",
        "        // Return the captured image data URL\n",
        "        return dataUrl;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Execute the JavaScript code\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "    # Call the JavaScript function to capture the image\n",
        "    data = eval_js('takePhoto(0.8)')\n",
        "\n",
        "    # Convert the captured image data URL to an OpenCV image\n",
        "    img = js_to_image(data)\n",
        "\n",
        "    # Save the captured image\n",
        "    filename = 'captured_image.jpg'\n",
        "    cv2.imwrite(filename, img)\n",
        "    print('Saved to {}'.format(filename))\n",
        "\n",
        "    # Display the captured image\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    # You can continue processing the captured image as needed\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "# initialize the Mediapipe face detection model\n",
        "mp_face_detection = mp.solutions.face_detection.FaceDetection()\n",
        "\n",
        "def detect_faces(image):\n",
        "    # convert the image to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # detect faces using Mediapipe face detection\n",
        "    results = mp_face_detection.process(image_rgb)\n",
        "\n",
        "    # extract face bounding boxes\n",
        "    faces = []\n",
        "    if results.detections:\n",
        "        for detection in results.detections:\n",
        "            bounding_box = detection.location_data.relative_bounding_box\n",
        "            image_height, image_width, _ = image.shape\n",
        "            x = int(bounding_box.xmin * image_width)\n",
        "            y = int(bounding_box.ymin * image_height)\n",
        "            w = int(bounding_box.width * image_width)\n",
        "            h = int(bounding_box.height * image_height)\n",
        "            faces.append((x, y, w, h))\n",
        "\n",
        "    return faces\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  # # get face bounding box coordinates using Haar Cascade\n",
        "  # faces = face_cascade.detectMultiScale(gray)\n",
        "  # # draw face bounding box on image\n",
        "  # for (x,y,w,h) in faces:\n",
        "  #     img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename\n",
        "\n",
        "  #Check if the choice is \"2\" (capture image from the camera)\n",
        "  if choice == \"2\":\n",
        "    try:\n",
        "      filename = take_photo('photo.jpg')\n",
        "      print('Saved to {}'.format(filename))\n",
        "\n",
        "      # Show the image which was just taken.\n",
        "      display(Image(filename))\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))"
      ],
      "metadata": {
        "id": "0G70QPb4jzkp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"Face Detection Program\")\n",
        "    print(\"----------------------\")\n",
        "    print(\"1. Upload an image\")\n",
        "    print(\"2. Capture an image from the camera\")\n",
        "    choice = input(\"Enter your choice (1 or 2): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        browse_photos()\n",
        "    elif choice == \"2\":\n",
        "        use_webcam()\n",
        "    else:\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "matqy7ySY8iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNvVvI77jeOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}